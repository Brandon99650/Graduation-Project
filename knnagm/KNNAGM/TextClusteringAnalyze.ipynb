{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def walkdir(root, filterOut=[])->list:\n",
    "    allfile = []\n",
    "    for dirpath, dirname, filename in os.walk(root):\n",
    "        for f in filename:\n",
    "            if f in filterOut:\n",
    "                continue\n",
    "            allfile.append(os.path.join(dirpath, f))\n",
    "    return allfile\n",
    "\n",
    "\n",
    "def write2dlist(filepath, twoDlst:list)->None:\n",
    "    with open(filepath, \"w+\") as output:\n",
    "        for sublst in tqdm(twoDlst):\n",
    "            for e in sublst:\n",
    "                output.write(f\"{e} \")\n",
    "            output.write(\"\\n\")\n",
    "    \n",
    "\n",
    "def read2dlist(filepath)->list:\n",
    "    ret = []\n",
    "    with open(filepath,\"r\") as input:\n",
    "        for line in input.readlines():\n",
    "            aline= []\n",
    "            for token in line.split(\" \"):\n",
    "                pureToken = token.strip()\n",
    "                if len(pureToken):\n",
    "                    aline.append(pureToken)\n",
    "            ret.append(aline)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result/attraction/K_5_7/clustering_result/kw\n",
      "result/attraction/K_5_7/clustering_result/eachC\n"
     ]
    }
   ],
   "source": [
    "data = \"attraction\"\n",
    "clusternum = 7\n",
    "clusters = f\"K_5_{clusternum}\"\n",
    "\n",
    "resultroot = os.path.join(\n",
    "    \"result\",data,clusters,\"clustering_result\"\n",
    ")\n",
    "\n",
    "kwdir = os.path.join(\n",
    "    resultroot,\"kw\"\n",
    ")\n",
    "if os.path.exists(kwdir):\n",
    "    print(kwdir)\n",
    "else:\n",
    "    raise FileExistsError(kwdir)\n",
    "\n",
    "\n",
    "clusterlstdir = os.path.join(\n",
    "    resultroot,\"eachC\"\n",
    ")\n",
    "\n",
    "if os.path.exists(clusterlstdir):\n",
    "    print(clusterlstdir)\n",
    "else:\n",
    "    raise FileExistsError(clusterlstdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clustering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file list generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwfiles = walkdir(kwdir,filterOut=\"all.kw\")\n",
    "clusterfiles = walkdir(clusterlstdir, filterOut='nonsen.txt')\n",
    "kwfiles.sort()\n",
    "clusterfiles.sort()\n",
    "cluster_with_kw = zip(clusterfiles, kwfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duplicate keywords for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 26.65it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(zip(clusterfiles, kwfiles), total=len(clusterfiles))\n",
    "topK = 15\n",
    "cid = 0\n",
    "dupdir = os.path.join(resultroot ,\"dupkw\")\n",
    "if not os.path.exists(dupdir):\n",
    "    os.mkdir(dupdir)\n",
    "\n",
    "for cdf, kwf in pbar:\n",
    "    kwbag = {}\n",
    "    attraction_name_lst = pd.read_csv(cdf, encoding='utf-8')['name'].tolist()\n",
    "    kws_lst = read2dlist(filepath=kwf)\n",
    "    if len(kws_lst) != len(attraction_name_lst):\n",
    "        print(f\"Not the same len !\\n{cdf}, {kwf}\")\n",
    "        break  \n",
    "\n",
    "    for docuid, kws in enumerate(kws_lst):\n",
    "        name = attraction_name_lst[docuid]\n",
    "        for k in kws:\n",
    "            \n",
    "            if k not in kwbag:\n",
    "                kwbag[k]=[1, [name]]\n",
    "            else: \n",
    "                kwbag[k][0] += 1\n",
    "                kwbag[k][1].append(name)\n",
    "\n",
    "    kwlst = []\n",
    "    for k, v in kwbag.items():\n",
    "        kwlst.append([k, v[0], v[1]])\n",
    "    kwlst.sort(key=lambda row: row[1], reverse=True)\n",
    "\n",
    "    with open(os.path.join(dupdir,f\"{cid}.kw\") ,\"w+\") as f:\n",
    "        for k in kwlst[:topK]:\n",
    "            f.write(f\"{k[0]}\\n\")\n",
    "\n",
    "    cid += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression to find important kw for wach cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.load(\"result/attraction/K_5_7/cluster.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['巧克力',\n",
       "  '建築',\n",
       "  '展場',\n",
       "  '工廠',\n",
       "  '宏亞',\n",
       "  '主題',\n",
       "  '陳列物',\n",
       "  '外觀',\n",
       "  '歷史',\n",
       "  '寓教',\n",
       "  '於樂',\n",
       "  '專業',\n",
       "  '廠館',\n",
       "  '外景',\n",
       "  '造型',\n",
       "  '文字',\n",
       "  '食品'],\n",
       " ['金屬',\n",
       "  '工廠',\n",
       "  '鋼金',\n",
       "  '部門',\n",
       "  '創意館',\n",
       "  '板金',\n",
       "  '產品',\n",
       "  '流程',\n",
       "  '品牌',\n",
       "  '館區',\n",
       "  '鋼鐵',\n",
       "  '協力',\n",
       "  '思維',\n",
       "  '決議',\n",
       "  '專業板',\n",
       "  '參觀',\n",
       "  '志鋼',\n",
       "  '電腦',\n",
       "  '作業',\n",
       "  '系統',\n",
       "  '手動',\n",
       "  '氣動',\n",
       "  '知性',\n",
       "  '光化',\n",
       "  '雷射',\n",
       "  '化生',\n",
       "  '文化',\n",
       "  '成形'],\n",
       " ['生態',\n",
       "  '泛舟',\n",
       "  '出海口',\n",
       "  '虹影',\n",
       "  '步道',\n",
       "  '阿美族',\n",
       "  '溪畔',\n",
       "  '長虹橋',\n",
       "  '姑巒',\n",
       "  '交際',\n",
       "  '地標',\n",
       "  '水鳥',\n",
       "  '季節',\n",
       "  '風景',\n",
       "  '時光',\n",
       "  '奚卜蘭',\n",
       "  '獅球嶼',\n",
       "  '綠意',\n",
       "  '小島',\n",
       "  '聖地',\n",
       "  '集塊',\n",
       "  '岩構',\n",
       "  '島嶼',\n",
       "  '鳥類',\n",
       "  '魚類',\n",
       "  '地點',\n",
       "  '下午茶',\n",
       "  '拱形',\n",
       "  '靠岸',\n",
       "  '山海']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwlist = read2dlist(filepath=os.path.join(kwdir, \"all.kw\"))\n",
    "kwlist[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4674/4674 [00:00<00:00, 119803.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kw_idx = {}\n",
    "idx_kw = {}\n",
    "idx = 0\n",
    "for ki in tqdm(kwlist):\n",
    "    for k in ki:\n",
    "        if k not in kw_idx:\n",
    "            kw_idx[k] = idx\n",
    "            idx_kw[idx] = k\n",
    "            idx += 1\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4674, 28887])\n"
     ]
    }
   ],
   "source": [
    "features = torch.zeros((labels.size()[0], idx), dtype=torch.float)\n",
    "\n",
    "print(features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for docid, ki in enumerate(kwlist):\n",
    "    for k in ki:\n",
    "        features[docid][kw_idx[k]] = 1\n",
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(features,os.path.join(resultroot, \"bow.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearR(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim) -> None:\n",
    "        super(LinearR, self).__init__()    \n",
    "        self.layer = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xi = self.layer(x)\n",
    "        return xi.sigmoid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearR(\n",
    "        in_dim=features.size()[1], \n",
    "        out_dim=labels.size()[1],\n",
    ").to(device)\n",
    "loss = torch.nn.BCELoss().to(device)\n",
    "optr = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:11<00:00, 168.60it/s, l=0.01]\n"
     ]
    }
   ],
   "source": [
    "bar = tqdm(range(2000))\n",
    "features = features.to(device)\n",
    "labels = labels.to(device)\n",
    "for e in bar :\n",
    "    model.train()\n",
    "    emd = model(x = features)\n",
    "    l = loss(emd, labels.type(torch.cuda.FloatTensor))\n",
    "    bar.set_postfix(ordered_dict={'l':f\"{l:.2f}\"})\n",
    "    optr.zero_grad()\n",
    "    l.backward()\n",
    "    optr.step()\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4619, -0.2177, -0.3714,  ..., -0.5320, -0.5333, -0.5314],\n",
      "        [-0.5270,  0.5075,  0.1233,  ..., -0.5062, -0.5130, -0.5108]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "weightlist = model.layer.weight\n",
    "weightlist = weightlist.cpu()\n",
    "print(weightlist[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4619, 0.2177, 0.3714,  ..., 0.5320, 0.5333, 0.5314],\n",
      "        [0.5270, 0.5075, 0.1233,  ..., 0.5062, 0.5130, 0.5108]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "abswlist = torch.abs(weightlist)\n",
    "print(abswlist[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6713, 1.4881, 1.4856], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c0_w = abswlist[0]\n",
    "v, i = torch.sort(c0_w, descending=True)\n",
    "print(v[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "遊樂行\n",
      "位在菓葉村的\n",
      "植面\n",
      "酸菜\n",
      "匯德\n",
      "嬸婆\n",
      "採獨棟\n",
      "航空公司\n",
      "卻是全\n",
      "甲區\n"
     ]
    }
   ],
   "source": [
    "i = i.tolist()\n",
    "for wordid  in i[:10]:\n",
    "    print(idx_kw[wordid])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22216b08ebab8be3394fec349c00ce696f41ecd13338106d20d108b8649c16c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
